# Homework 4

**Task:**  
Create an RAG (Retrieval-Augmented Generation) system based on an arbitrary embedding model, vector store, and LLM model.

---

## Acceptance Criteria
- Set up a pipeline connecting a dense embedding model with a vector store and link it with an LLM.
- Follow the schemas provided in the [presentation](https://docs.google.com/presentation/d/1vuU7655vL2q1e0fzE6nwDTeT5TnB6ZnG5qHuSVZo1hQ/edit?usp=sharing).
- During the presentation, you will be asked to demonstrate the system live (CLI is sufficient; no frontend required).
- Usage of external API-served LLMs (e.g., GPT-4) is allowed.  
- **Important:** External embedding models served through APIs are **not allowed**.  
- Local LLM usage is appreciated.

---

## Points
- This exercise grants **0.5 points**.

---

## Useful Links
- For those crazy enough wanting to have frontend:
  [Streamlit LLM Conversational Apps Tutorial](https://docs.streamlit.io/develop/tutorials/llms/build-conversational-apps)
- Link to presentation from classes:  
  [Class Presentation](https://docs.google.com/presentation/d/1vuU7655vL2q1e0fzE6nwDTeT5TnB6ZnG5qHuSVZo1hQ/edit?usp=sharing)
- Other useful resources:
  - [LangChain RAG Tutorial](https://python.langchain.com/docs/tutorials/rag/)
  - [Sentence Transformers (SBERT)](https://sbert.net/)
  - [MTEB Leaderboard on Hugging Face](https://huggingface.co/spaces/mteb/leaderboard)
